{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tN6jsoIxZrGv",
        "outputId": "a73bbdca-84db-47c6-b15a-7e6cea55d752"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount = True)\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from scipy import signal\n",
        "from PIL import Image, ImageOps\n",
        "from google.colab.patches import cv2_imshow\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ACafdDV7LKe9"
      },
      "outputs": [],
      "source": [
        "# edit the part after /content/drive/ with the Google Drive directories you want to use for images, inferences and classifier model\n",
        "imageDirectory = \"<path to image directory>/\"\n",
        "inferencesDirectory = \"<path to inferences directory>/\"\n",
        "modelDirectory = \"<path to directory model is in>/not egg-egg model/model\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "J-fhSaG9K-MX"
      },
      "outputs": [],
      "source": [
        "def getBorders(cv2Image):\n",
        "  src = cv2.cvtColor(cv2Image, cv2.COLOR_BGR2GRAY)\n",
        "  src = cv2.blur(src,(src.shape[1], 1))\n",
        "  src = cv2.adaptiveThreshold(src,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV,101,2)\n",
        "  # cv2_imshow(src)\n",
        "  points = np.sum(src, axis = 1)\n",
        "  points = signal.savgol_filter(points, 300, 2)\n",
        "  # plt.cla()\n",
        "  # plt.plot(range(len(points)), points)\n",
        "  peaks, _ = signal.find_peaks(points, distance = 1000)\n",
        "  # plt.plot(peaks[0], points[peaks[0]], \"x\")\n",
        "  # plt.plot(peaks[-1], points[peaks[-1]], \"x\")\n",
        "  row1 = peaks[0]\n",
        "  row2 = peaks[-1]\n",
        "  src = cv2.cvtColor(cv2Image, cv2.COLOR_BGR2GRAY)\n",
        "  src = cv2.blur(src,(1, src.shape[0]))\n",
        "  src = cv2.adaptiveThreshold(src,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV,101,2)\n",
        "  # cv2_imshow(src)\n",
        "  points = np.sum(src, axis = 0)\n",
        "  points = signal.savgol_filter(points, 300, 2)\n",
        "  # plt.plot(range(len(points)), points)\n",
        "  peaks, _ = signal.find_peaks(points, distance = 700)\n",
        "  # plt.plot(peaks[0], points[peaks[0]], \"x\")\n",
        "  # plt.plot(peaks[-1], points[peaks[-1]], \"x\")\n",
        "  column1 = peaks[0]\n",
        "  column2 = peaks[-1]\n",
        "  if(abs((column2 - column1) - 4365) > 200):\n",
        "    print(\"col corrected\")\n",
        "    column1 = 227\n",
        "    column2 = 4643\n",
        "  if(abs((row2 - row1) - 2100) > 150):\n",
        "    print(\"row corrected\")\n",
        "    row1 = 725\n",
        "    row2 = 2979\n",
        "  return([row1, row2, column1, column2])\n",
        "\n",
        "def tupleToList(t):\n",
        "    return list(map(tupleToList, t)) if isinstance(t, (list, tuple)) else t\n",
        "\n",
        "def cropSquareFromContour(c, img):\n",
        "\n",
        "    rect = cv2.minAreaRect(c)\n",
        "\n",
        "    rect = tupleToList(rect)\n",
        "    rect[1][0] = max(rect[1])\n",
        "    rect[1][1] = max(rect[1])\n",
        "\n",
        "    box = cv2.boxPoints(rect)\n",
        "    box = np.intp(box)\n",
        "\n",
        "    width = int(rect[1][0])\n",
        "    height = int(rect[1][1])\n",
        "\n",
        "    src_pts = box.astype(\"float32\")\n",
        "    dst_pts = np.array([[0, height-1],\n",
        "                        [0, 0],\n",
        "                        [width-1, 0],\n",
        "                        [width-1, height-1]], dtype=\"float32\")\n",
        "\n",
        "    M = cv2.getPerspectiveTransform(src_pts, dst_pts)\n",
        "    warped = cv2.warpPerspective(img, M, (width, height))\n",
        "\n",
        "    return warped\n",
        "\n",
        "def cropRectangleFromContour(c, img):\n",
        "\n",
        "    rect = cv2.minAreaRect(c)\n",
        "\n",
        "    box = cv2.boxPoints(rect)\n",
        "    box = np.intp(box)\n",
        "    width = int(rect[1][0])\n",
        "    height = int(rect[1][1])\n",
        "\n",
        "    src_pts = box.astype(\"float32\")\n",
        "    dst_pts = np.array([[0, height-1],\n",
        "                        [0, 0],\n",
        "                        [width-1, 0],\n",
        "                        [width-1, height-1]], dtype=\"float32\")\n",
        "    M = cv2.getPerspectiveTransform(src_pts, dst_pts)\n",
        "    warped = cv2.warpPerspective(img, M, (width, height))\n",
        "\n",
        "    return warped\n",
        "\n",
        "# def classifyObject(image):\n",
        "#   image = cv2.resize(image, (224, 224), interpolation=cv2.INTER_AREA)\n",
        "#   image = np.asarray(image, dtype=np.float32).reshape(1, 224, 224, 3)\n",
        "#   # image = (image / 127.5) - 1\n",
        "#   image = image / 255\n",
        "#   prediction = model.predict(image, verbose = 0)\n",
        "#   return(prediction)\n",
        "\n",
        "def classifyObject(cv2Image):\n",
        "  img = cv2Image\n",
        "  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "  img = Image.fromarray(img)\n",
        "  width_height_tuple = (224, 224)\n",
        "  width, height = img.size\n",
        "  target_width, target_height = width_height_tuple\n",
        "  crop_height = (width * target_height) // target_width\n",
        "  crop_width = (height * target_width) // target_height\n",
        "  crop_height = min(height, crop_height)\n",
        "  crop_width = min(width, crop_width)\n",
        "  crop_box_hstart = (height - crop_height) // 2\n",
        "  crop_box_wstart = (width - crop_width) // 2\n",
        "  crop_box_wend = crop_box_wstart + crop_width\n",
        "  crop_box_hend = crop_box_hstart + crop_height\n",
        "  crop_box = [\n",
        "      crop_box_wstart, crop_box_hstart, crop_box_wend,\n",
        "      crop_box_hend\n",
        "  ]\n",
        "  img = img.resize(width_height_tuple, Image.NEAREST, box=crop_box)\n",
        "  my_image = img_to_array(img)\n",
        "  my_image = my_image.reshape((1, my_image.shape[0], my_image.shape[1], my_image.shape[2]))\n",
        "  my_image = my_image / 255.\n",
        "  prediction = model(my_image)\n",
        "  return(prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "k-PLFolpYXH3"
      },
      "outputs": [],
      "source": [
        "def countImage(imagePath):\n",
        "  img = cv2.imread(imagePath)\n",
        "  thisBorders = getBorders(img)\n",
        "\n",
        "  # Convert to grayscale for binarization later\n",
        "  img_gray = cv2.imread(imagePath, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "  # Binarize image with adaptive threshold\n",
        "  thres = cv2.adaptiveThreshold(img_gray,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
        "              cv2.THRESH_BINARY_INV,101,2)\n",
        "\n",
        "  #  TUNE: KERNEL SIZE\n",
        "  # Preprocess image, morphologically open image, removes small spots\n",
        "  kernel = np.ones((7, 7), np.uint8)\n",
        "  thres = cv2.morphologyEx(thres, cv2.MORPH_OPEN, kernel)\n",
        "\n",
        "  # plt.figure()\n",
        "  # plt.imshow(img)\n",
        "  # plt.figure()\n",
        "  # plt.imshow(thres)\n",
        "\n",
        "  # Get all contours\n",
        "  cnts, _ = cv2.findContours(thres, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "  cnts_filtered = []\n",
        "\n",
        "  for c in cnts:\n",
        "    area = cv2.contourArea(c)\n",
        "\n",
        "    # TUNE: AREA THRESHOLD\n",
        "    # Filter by area\n",
        "    if(area < 4000 and area > 1500):\n",
        "        width = min(cv2.minAreaRect(c)[1])\n",
        "        length = max(cv2.minAreaRect(c)[1])\n",
        "\n",
        "        # TUNE: L, W, LW THRESHOLD\n",
        "        if(length > 40 and length < 150 and length/width > 1.5 and length/width < 5):\n",
        "\n",
        "          thisObject = cropSquareFromContour(c, img)\n",
        "\n",
        "          modelClasses = (\"egg\", \"not egg\")\n",
        "          for i in range(4):\n",
        "            prediction = modelClasses[np.argmax(classifyObject(thisObject))]\n",
        "            if prediction == \"not egg\":\n",
        "              break\n",
        "            thisObject = cv2.rotate(thisObject, cv2.ROTATE_90_CLOCKWISE)\n",
        "\n",
        "          if(prediction == \"egg\"):\n",
        "              objectIsInFrame = (\n",
        "                thisBorders[0] < c.flatten()[1] < thisBorders[1] and\n",
        "                thisBorders[2] < c.flatten()[0] < thisBorders[3]\n",
        "                )\n",
        "              if(objectIsInFrame):\n",
        "                cnts_filtered.append(c)\n",
        "          else:\n",
        "            pass\n",
        "\n",
        "  count = len(cnts_filtered)\n",
        "  cv2.rectangle(img, (thisBorders[2], thisBorders[0]), (thisBorders[3], thisBorders[1]), 1, 10)\n",
        "  cv2.drawContours(img, cnts_filtered, -1, (0,255, 20), 6)\n",
        "  img = cv2.putText(img, 'Egg count: ' + str(count), (100, 100), 1, 8, 1, 10)\n",
        "\n",
        "  return count, img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LJ0M5OhiPEkb",
        "outputId": "cfa7ee2c-0309-4d86-8d40-d87be11fb435"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Empty DataFrame\n",
            "Columns: [imageCode, count]\n",
            "Index: []\n"
          ]
        }
      ],
      "source": [
        "# model = tf.keras.models.load_model(modelDirectory)\n",
        "model = tf.keras.layers.TFSMLayer(modelDirectory, call_endpoint='serving_default')\n",
        "if(\"inferencesInProgress.csv\" in os.listdir(inferencesDirectory)):\n",
        "  inferences = pd.read_csv(os.path.join(inferencesDirectory, \"inferencesInProgress.csv\"))\n",
        "else:\n",
        "  inferences = pd.DataFrame(columns = ['imageCode', 'count'])\n",
        "print(inferences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YnMgQLwYK_25",
        "outputId": "4f5fee4e-54e5-4d08-8ea2-1b5bb563fa04"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Copy of M. javanica3rdTrial0005.jpg\n",
            "row corrected\n",
            "9\n",
            "111\n",
            "Copy of M. javanica3rdTrial0005.jpg\n",
            "Copy of M. javanica3rdTrial0001.jpg\n",
            "9\n",
            "91\n",
            "Copy of M. javanica3rdTrial0001.jpg\n",
            "Copy of M. javanica3rdTrial0012.jpg\n",
            "9\n",
            "43\n",
            "Copy of M. javanica3rdTrial0012.jpg\n",
            "Copy of M. javanica3rdTrial0019.jpg\n",
            "9\n",
            "4\n",
            "Copy of M. javanica3rdTrial0019.jpg\n",
            "Copy of M. javanica3rdTrial0015.jpg\n",
            "9\n",
            "45\n",
            "Copy of M. javanica3rdTrial0015.jpg\n",
            "Copy of M. javanica3rdTrial0016.jpg\n",
            "row corrected\n",
            "9\n",
            "34\n",
            "Copy of M. javanica3rdTrial0016.jpg\n",
            "Copy of M. javanica3rdTrial0014.jpg\n",
            "done\n"
          ]
        }
      ],
      "source": [
        "with tf.device('/device:GPU:0'):\n",
        "  try:\n",
        "    for file in os.listdir(imageDirectory):\n",
        "\n",
        "      thisImageCode = str(os.path.splitext(os.path.basename(file))[0])\n",
        "      if((thisImageCode + \".jpg\") in list(inferences['imageCode'])):\n",
        "        continue\n",
        "\n",
        "      print(file)\n",
        "\n",
        "      full_file = os.path.join(imageDirectory, file)\n",
        "      count, img = countImage(full_file)\n",
        "      print(9)\n",
        "      inferences.loc[inferences.shape[0]] = [file, count]\n",
        "\n",
        "      print(str(count))\n",
        "\n",
        "      print(file)\n",
        "\n",
        "      cv2.imwrite(os.path.join(inferencesDirectory, file), img)\n",
        "      inferences.to_csv(os.path.join(inferencesDirectory, 'inferencesInProgress.csv'), index = False)\n",
        "\n",
        "      count, img, full_file, thisImageCode = None, None, None, None\n",
        "  except:\n",
        "    pass\n",
        "\n",
        "print(\"done\")\n",
        "inferences.to_csv(os.path.join(inferencesDirectory, 'inferences.csv'), index = False)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
